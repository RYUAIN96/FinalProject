{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 목표 : 머신러닝 돌리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 직접 분류한 리뷰로 머신러닝 돌리기 => 정확도 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_1 = pd.read_csv(\"./data/sentiment_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_1 = sentiment_1.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>P/N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We’d never had Korean before and I’d been want...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really was unsure of how much of the menu wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Absolutely delicious authentic Korean food ser...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  P/N\n",
       "0  We’d never had Korean before and I’d been want...    1\n",
       "1  I really was unsure of how much of the menu wo...    1\n",
       "2  Absolutely delicious authentic Korean food ser...    1"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\admin\\anaconda3\\lib\\site-packages (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\admin\\anaconda3\\lib\\site-packages (from nltk) (1.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from time import time\n",
    "\n",
    "# 전처리 작업을 위해 호출될 함수\n",
    "def preprocessor(text) :\n",
    "    # 문자열의 내의 html 태그를 삭제한다.\n",
    "    # 문자열에서 이모티콘을 찾아낸다.\n",
    "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)|\\^.?\\^', str(text))\n",
    "    # 문장에서 특수문자를 제거하고\n",
    "    # 문자열을 소문자로 변하고\n",
    "    # 추출한 이모티콘을 붙혀준다.\n",
    "    text = re.sub('[\\W]+', ' ', str(text).lower() + ' '.join(emoticons).replace('-', ''))\n",
    "    # print(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sentiment_1[\"review\"] = sentiment_1[\"review\"].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_1.to_csv(\"./data/refined_review.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>P/N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we d never had korean before and i d been want...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i really was unsure of how much of the menu wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolutely delicious authentic korean food ser...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the banchan or side dishes that they serve are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my eleven year old twins beg to get biminbop o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  P/N\n",
       "0  we d never had korean before and i d been want...    1\n",
       "1  i really was unsure of how much of the menu wo...    1\n",
       "2  absolutely delicious authentic korean food ser...    1\n",
       "3  the banchan or side dishes that they serve are...    1\n",
       "4  my eleven year old twins beg to get biminbop o...    1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_review = pd.read_csv(\"./data/refined_review.csv\")\n",
    "refined_review.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def step2_preprocessing() :\n",
    "#     # csv 데이터를 읽어온다.\n",
    "#     df = pd.read_csv('./data/trip_final.csv')\n",
    "\n",
    "#     # 전처리 작업\n",
    "#     stime = time()\n",
    "#     print('전처리 시작')\n",
    "#     df[\"review\"] = df['review'].apply(preprocessor)\n",
    "#     print('전처리 완료')\n",
    "#     print('소요시간 : %d' % (time() - stime))\n",
    "\n",
    "#     # 전처리된 데이터를 저장한다.\n",
    "#     df.to_csv('./data/pre_review.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 평점 전처리\n",
    "# def star_proprocessing(text) :\n",
    "#     value = int(text)\n",
    "#     if value <= 3.0 :\n",
    "#         return '0'\n",
    "#     else :\n",
    "#         return '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def step2_preprocessing():\n",
    "#     # 수집한 데이터를 읽어온다.\n",
    "#     df = pd.read_csv('./data/trip_final.csv')\n",
    "#     # print(df)\n",
    "\n",
    "#     # 전처리 과정\n",
    "#     df['rating'] = df['rating'].apply(star_proprocessing)\n",
    "#     # 학습 데이터와 테스트 데이터로 나눈다.\n",
    "#     text_list = df['review'].tolist()\n",
    "#     star_list = df['rating'].tolist()\n",
    "\n",
    "#     text_train, text_test, star_train, star_test = train_test_split(text_list, star_list, test_size=0.3, random_state=0)\n",
    "#     #print(len(text_train))\n",
    "#     #print(len(text_test))\n",
    "#     #print(len(star_train))\n",
    "#     #print(len(star_test))\n",
    "\n",
    "#     # 저장한다.\n",
    "#     dic_train = {\n",
    "#         'text' : text_train,\n",
    "#         'star' : star_train\n",
    "#     }\n",
    "#     df_tran = pd.DataFrame(dic_train)\n",
    "\n",
    "#     dic_test = {\n",
    "#         'text' : text_test,\n",
    "#         'star' : star_test\n",
    "#     }\n",
    "#     df_test = pd.DataFrame(dic_test)\n",
    "\n",
    "#     df_tran.to_csv('./data/trip_train_data.csv', index=False)\n",
    "#     df_test.to_csv('./data/trip_test_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "step2_preprocessing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\admin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# step3_word_tokenizer.py\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "\n",
    "# stopword 단어 사전을 다운로드 받는다.\n",
    "nltk.download('stopwords')\n",
    "# stopword 데이터를 가져온다.\n",
    "stop = stopwords.words('english')\n",
    "# 단어 줄기를 하기위한 객체\n",
    "porter = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 공백으로 단어분리\n",
    "def tokenizer(text) :\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어줄기\n",
    "def tokenizer_porter(text) :\n",
    "    return [porter.stem(word) for word in text.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_stopwordsr(text) :\n",
    "    # 띄어쓰기를 기준으로 분리한다.\n",
    "    word_list = text.split()\n",
    "    #단어 줄기 처리\n",
    "    word_list2 = \\\n",
    "        [porter.stem(word) for word in word_list]\n",
    "    #불용어 처리\n",
    "    result = []\n",
    "    for w in word_list2: \n",
    "        if w not in stop: \n",
    "            result.append(w)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step3_word_tokenizer() :\n",
    "    text = 'runners like running and thus they run'\n",
    "\n",
    "    a1 = tokenizer(text)\n",
    "    a2 = tokenizer_porter(text)\n",
    "    print('a1 :', a1)\n",
    "    print('a2 :', a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pickle\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step4_learning() :\n",
    "    # csv 파일에서 데이터를 읽어온다.\n",
    "    df = pd.read_csv('./data/refined_review.csv')\n",
    "    # 테스트, 학습데이터로 나눈다.\n",
    "    X_train = df.loc[:700 - 1, 'review'].values\n",
    "    y_train = df.loc[:700 - 1, 'P/N'].values\n",
    "\n",
    "    X_test = df.loc[300:, 'review'].values\n",
    "    y_test = df.loc[300:, 'P/N'].values\n",
    "\n",
    "    # 단어장을 만들어주는 객체 생성\n",
    "    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "    # tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer_stopwordsr)\n",
    "    # 데이터를 학습하기 위한 객체\n",
    "    logistic = LogisticRegression(C=10.0, penalty='l2', random_state=0)\n",
    "    # 파이프 라인 설정\n",
    "    pipeline = Pipeline([('vect', tfidf), ('clf', logistic)])\n",
    "\n",
    "    # 학습한다.\n",
    "    stime = time()\n",
    "    print('학습 시작')\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print('학습 종료')\n",
    "    print('총 학습시간 : %d' % (time() - stime))\n",
    "\n",
    "    # 테스트\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"정확도 : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # 성능 확인\n",
    "    y_true = y_test\n",
    "    y_hat = y_pred\n",
    "    print(\"R2 score : \", r2_score(y_true, y_hat))\n",
    "    print(\"mean_absolute_error : \", mean_absolute_error(y_true, y_hat))\n",
    "    print(\"mean_squared_error : \", mean_squared_error(y_true, y_hat))\n",
    "\n",
    "    # 학습이 완료된 객체를 저장한다.\n",
    "    with open('./data/trip.dat', 'wb') as fp :\n",
    "        pickle.dump(pipeline, fp)\n",
    "\n",
    "    print('저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작\n",
      "학습 종료\n",
      "총 학습시간 : 0\n",
      "정확도 : 0.951\n",
      "R2 score :  0.4861405405405407\n",
      "mean_absolute_error :  0.04864091559370529\n",
      "mean_squared_error :  0.04864091559370529\n",
      "저장완료\n"
     ]
    }
   ],
   "source": [
    "step4_learning()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 별점으로 긍정부정 머신러닝 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_2 = pd.read_csv(\"./data/sentiment_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_2 = sentiment_2.drop([\"Unnamed: 0\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_2[\"review\"] = sentiment_2[\"review\"].apply(preprocessor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_2.to_csv(\"./data/refined_review_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "refined_review_2 = refined_review_2.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_review_2.to_csv(\"./data/refined_review_2.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>P/N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>we d never had korean before and i d been want...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>i really was unsure of how much of the menu wo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>absolutely delicious authentic korean food ser...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the banchan or side dishes that they serve are...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>my eleven year old twins beg to get biminbop o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  P/N\n",
       "0  we d never had korean before and i d been want...    1\n",
       "1  i really was unsure of how much of the menu wo...    1\n",
       "2  absolutely delicious authentic korean food ser...    1\n",
       "3  the banchan or side dishes that they serve are...    1\n",
       "4  my eleven year old twins beg to get biminbop o...    1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_review_2 = pd.read_csv(\"./data/refined_review_2.csv\")\n",
    "refined_review_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review    0\n",
       "P/N       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "refined_review_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "refined_review_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step4_learning() :\n",
    "    # csv 파일에서 데이터를 읽어온다.\n",
    "    df = pd.read_csv('./data/refined_review_2.csv')\n",
    "    # 테스트, 학습데이터로 나눈다.\n",
    "    X_train = df.loc[:35000, 'review'].values\n",
    "    y_train = df.loc[:35000, 'P/N'].values\n",
    "\n",
    "    X_test = df.loc[15000:, 'review'].values\n",
    "    y_test = df.loc[15000:, 'P/N'].values\n",
    "\n",
    "    # 단어장을 만들어주는 객체 생성\n",
    "    tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer)\n",
    "    # tfidf = TfidfVectorizer(lowercase=False, tokenizer=tokenizer_stopwordsr)\n",
    "    # 데이터를 학습하기 위한 객체\n",
    "    logistic = LogisticRegression(C=10.0, penalty='l2', random_state=0)\n",
    "    # 파이프 라인 설정\n",
    "    pipeline = Pipeline([('vect', tfidf), ('clf', logistic)])\n",
    "\n",
    "    # 학습한다.\n",
    "    stime = time()\n",
    "    print('학습 시작')\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    print('학습 종료')\n",
    "    print('총 학습시간 : %d' % (time() - stime))\n",
    "\n",
    "    # 테스트\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"정확도 : %.3f\" % accuracy_score(y_test, y_pred))\n",
    "\n",
    "    # 성능 확인\n",
    "    y_true = y_test\n",
    "    y_hat = y_pred\n",
    "    print(\"R2 score : \", r2_score(y_true, y_hat))\n",
    "    print(\"mean_absolute_error : \", mean_absolute_error(y_true, y_hat))\n",
    "    print(\"mean_squared_error : \", mean_squared_error(y_true, y_hat))\n",
    "\n",
    "    # 학습이 완료된 객체를 저장한다.\n",
    "    with open('./data/trip_2.dat', 'wb') as fp :\n",
    "        pickle.dump(pipeline, fp)\n",
    "\n",
    "    print('저장완료')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 시작\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습 종료\n",
      "총 학습시간 : 2\n",
      "정확도 : 0.898\n",
      "R2 score :  0.38259795409770103\n",
      "mean_absolute_error :  0.10150583986252294\n",
      "mean_squared_error :  0.10150583986252294\n",
      "저장완료\n"
     ]
    }
   ],
   "source": [
    "step4_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
